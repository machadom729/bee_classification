{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "1\n",
    "import pandas as pd\n",
    "import librosa as la\n",
    "import librosa.display as ld\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Zero Zero\n",
      "\n",
      "numpy     : 1.23.5\n",
      "matplotlib: 3.7.1\n",
      "librosa   : 0.10.0.post2\n",
      "seaborn   : 0.12.2\n",
      "pandas    : 2.0.0\n",
      "sklearn   : 1.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Zero Zero\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.join(name) for name in os.listdir(\"./data\")]\n",
    "paths_bee = []\n",
    "paths_no_bee = []\n",
    "for path in paths:\n",
    "if \"No_Bee\" in path:\n",
    "paths_no_bee.append(path)\n",
    "else:\n",
    "paths_bee.append(path)\n",
    "len(paths_no_bee), len(paths_bee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.randint(0, len(paths_bee))\n",
    "data, sr = la.load(f\"./data/{paths_bee[rnd]}\", sr=44100, res_type=\"kaiser_best\")\n",
    "print(\"Canais \", len(data.shape))\n",
    "print(\"# total de amostras \", data.shape[0])\n",
    "print(\"Arquivo: \", paths_bee[rnd])\n",
    "print(\"Taxa de amostragem \", sr)\n",
    "print(\"Duração \", la.get_duration(y=data, sr=sr))\n",
    "Audio(data=data, rate=sr)\n",
    "# plt.title(\"SOM ABELHA\", size=16)\n",
    "# ld.waveshow(y=data, sr=sr)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnd = np.random.randint(0, len(paths_bee))\n",
    "# data, sr = la.load(f\"./data/{paths_bee[rnd]}\", sr=44100, res_type=\"kaiser_best\")\n",
    "# stft = la.stft(data)\n",
    "# stft_db = la.amplitude_to_db(np.abs(stft))\n",
    "# ld.specshow(stft_db, x_axis=\"time\", y_axis=\"log\", cmap=\"Spectral\")\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnd = np.random.randint(0, len(paths_bee))\n",
    "# data, sr = la.load(f\"./data/{paths_bee[rnd]}\", sr=44100, res_type=\"kaiser_best\")\n",
    "# mfccs = la.feature.mfcc(y=data, sr=sr, n_mfcc=40)\n",
    "# mfccs_db = la.amplitude_to_db(np.abs(mfccs))\n",
    "# ld.specshow(mfccs_db, x_axis=\"time\", y_axis=\"log\", cmap=\"Spectral\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.randint(0, len(paths_no_bee))\n",
    "data, sr = la.load(f\"./data/{paths_no_bee[rnd]}\", sr=44100, res_type=\"kaiser_best\")\n",
    "\n",
    "print(\"Canais \", len(data.shape))\n",
    "print(\"# total de amostras \", data.shape[0])\n",
    "print(\"Arquivo: \", paths_no_bee[rnd])\n",
    "print(\"Taxa de amostragem \", sr)\n",
    "print(\"Duração \", la.get_duration(y=data, sr=sr))\n",
    "Audio(data=data, rate=sr)\n",
    "# plt.title(\"SOM SEM ABELHA\", size=16)\n",
    "# ld.waveshow(y=data, sr=sr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnd = np.random.randint(0, len(paths_no_bee))\n",
    "# data, sr = la.load(f\"./data/{paths_no_bee[rnd]}\", sr=44100,␣\n",
    "↪res_type=\"kaiser_best\")\n",
    "# stft = la.stft(data)\n",
    "# stft_db = la.amplitude_to_db(np.abs(stft))\n",
    "# plt.show(ld.specshow(stft_db, x_axis=\"time\", y_axis=\"log\", cmap=\"Spectral\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnd = np.random.randint(0, len(paths_no_bee))\n",
    "# data, sr = la.load(f\"./data/{paths_no_bee[rnd]}\", sr=44100,␣\n",
    "↪res_type=\"kaiser_best\")\n",
    "# mfccs = la.feature.mfcc(y=data, sr=sr, n_mfcc=40)\n",
    "# mfccs_db = la.amplitude_to_db(np.abs(mfccs))\n",
    "# ld.specshow(mfccs_db, x_axis=\"time\", y_axis=\"log\", cmap=\"Spectral\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extrator(file_name):\n",
    "    data, sample_rate = la.load(f\"./data/{file_name}\", sr=44100, res_type=\"kaiser_best\")\n",
    "    mfccs_features = la.feature.mfcc(y=data, sr= sample_rate, n_mfcc=40)\n",
    "    mfccs_features_scaled = np.mean(mfccs_features.T, axis=0)\n",
    "    return mfccs_features_scaled\n",
    "\n",
    "extracted_features_bee = []\n",
    "extracted_features_nobee = []\n",
    "\n",
    "for path in tqdm(paths_bee):\n",
    "    try:\n",
    "        data = features_extrator(path)\n",
    "        extracted_features_bee.append(data)\n",
    "    except:\n",
    "        print(path)\n",
    "        continue\n",
    "    \n",
    "for path in tqdm(paths_no_bee):\n",
    "    try:\n",
    "        data = features_extrator(path)\n",
    "        extracted_features_nobee.append(data)\n",
    "    except:\n",
    "        print(path)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_features_bee), len(extracted_features_nobee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"feature\": extracted_features_bee, \"class\": 1})\n",
    "df2 = pd.DataFrame({\"feature\": extracted_features_nobee, \"class\": 0})\n",
    "data = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[\"feature\"].tolist())\n",
    "y = np.array(data[\"class\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "predict = clf_lr.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(X_train, y_train)\n",
    "predict = clf_nb.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_train, y_train)\n",
    "predict = clf_knn.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train, y_train)\n",
    "predict = clf_rf.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = SVC()\n",
    "clf_svm.fit(X_train, y_train)\n",
    "predict = clf_svm.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"lr\", LogisticRegression()),\n",
    "(\"svm\", SVC()),\n",
    "(\"rf\", RandomForestClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_st = StackingClassifier(estimators=estimators)\n",
    "clf_st.fit(X_train, y_train)\n",
    "predict = clf_st.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_vt = VotingClassifier(estimators=estimators)\n",
    "clf_vt.fit(X_train, y_train)\n",
    "predict = clf_vt.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))\n",
    "print(classification_report(y_test, predict))\n",
    "confusion_matrix(y_test, predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
